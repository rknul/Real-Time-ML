{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "t_XDUQTMypM6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "wb4J0n7kZHHN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
        ")\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(cifar_trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(cifar_testset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quThl62I-kr_",
        "outputId": "dcd8ffed-5942-4d20-d48c-05b1284b84a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "ZONEqXpQBpOQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1 Part 1"
      ],
      "metadata": {
        "id": "sAE3G0Fwi9-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGGBase(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGGBase, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.layer8(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "kCDn7LebNvSd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters again\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = VGGBase(num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "steps = len(trainloader)"
      ],
      "metadata": {
        "id": "1TvWUHi1FL-Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist = []\n",
        "loss_val_hist = []\n",
        "acc_val_hist = []"
      ],
      "metadata": {
        "id": "MrpIsdF8YLQP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  tl = 0\n",
        "  vl = 0\n",
        "  va = 0\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tl = tl + loss.item()\n",
        "\n",
        "  tl = tl/len(trainloader)\n",
        "  loss_train_hist.append(tl)\n",
        "  print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, steps, loss.item()))\n",
        "  \n",
        "  #Validation\n",
        "  with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      vl += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      accuracy += (predicted == labels).sum().item()\n",
        "      del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %' .format(5000, 100*accuracy / total))\n",
        "    vl = vl/len(testloader)\n",
        "    loss_val_hist.append(vl)\n",
        "    va = accuracy/total\n",
        "    acc_val_hist.append(va)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MYt0zpLFxyT",
        "outputId": "806d3ea6-dac9-40d9-edf1-e20045311f0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [391/391], Loss: 1.5173\n",
            "Accuracy of the network on the 5000 validation images: 43.03 %\n",
            "Epoch [2/10], Step [391/391], Loss: 1.2889\n",
            "Accuracy of the network on the 5000 validation images: 56.01 %\n",
            "Epoch [3/10], Step [391/391], Loss: 0.9392\n",
            "Accuracy of the network on the 5000 validation images: 64.16 %\n",
            "Epoch [4/10], Step [391/391], Loss: 0.9910\n",
            "Accuracy of the network on the 5000 validation images: 66.16 %\n",
            "Epoch [5/10], Step [391/391], Loss: 0.7537\n",
            "Accuracy of the network on the 5000 validation images: 69.01 %\n",
            "Epoch [6/10], Step [391/391], Loss: 0.8636\n",
            "Accuracy of the network on the 5000 validation images: 70.75 %\n",
            "Epoch [7/10], Step [391/391], Loss: 0.4740\n",
            "Accuracy of the network on the 5000 validation images: 73.44 %\n",
            "Epoch [8/10], Step [391/391], Loss: 0.7346\n",
            "Accuracy of the network on the 5000 validation images: 74.86 %\n",
            "Epoch [9/10], Step [391/391], Loss: 0.5961\n",
            "Accuracy of the network on the 5000 validation images: 74.87 %\n",
            "Epoch [10/10], Step [391/391], Loss: 0.5203\n",
            "Accuracy of the network on the 5000 validation images: 75.17 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Loss: \", loss_train_hist)\n",
        "print(\"Validation Loss: \", loss_val_hist)\n",
        "print(\"Validation Accuracy: \", acc_val_hist)"
      ],
      "metadata": {
        "id": "xpAf69bz0Qsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b33d96-d285-4965-d785-3d8eb31330a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  [1.8099597893712465, 1.2996049556890716, 1.0738227234776978, 0.9169404714003854, 0.8066265424499122, 0.7146925236410497, 0.6390998580724078, 0.5734735846214587, 0.5160492311810594, 0.4631518668225964]\n",
            "Validation Loss:  [1.475914283643795, 1.1995902649963959, 1.005139410495758, 0.9557124263123621, 0.8846339251421675, 0.8322402027588857, 0.7678028578999676, 0.7359243495554864, 0.7303075405615794, 0.7439083683339855]\n",
            "Validation Accuracy:  [0.4303, 0.5601, 0.6416, 0.6616, 0.6901, 0.7075, 0.7344, 0.7486, 0.7487, 0.7517]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrVe3g2omQNn",
        "outputId": "1af96dad-5253-495f-a9f9-3f0aa0a1e6aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ptflops in /usr/local/lib/python3.9/dist-packages (0.6.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from ptflops) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->ptflops) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1 Part 2"
      ],
      "metadata": {
        "id": "6Rmh76FWi23U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer10 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer11 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer12 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer13 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.layer8(out)\n",
        "        out = self.layer9(out)\n",
        "        out = self.layer10(out)\n",
        "        out = self.layer11(out)\n",
        "        out = self.layer12(out)\n",
        "        out = self.layer13(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "DJj7ui1DibUI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters again\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = VGG16(num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "steps = len(trainloader)"
      ],
      "metadata": {
        "id": "8W-HHfQjjnB-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist16 = []\n",
        "loss_val_hist16 = []\n",
        "acc_val_hist16 = []"
      ],
      "metadata": {
        "id": "gSQSBZ1zjOe7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  tl = 0\n",
        "  vl = 0\n",
        "  va = 0\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tl = tl + loss.item()\n",
        "\n",
        "  tl = tl/len(trainloader)\n",
        "  loss_train_hist16.append(tl)\n",
        "  print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, steps, loss.item()))\n",
        "  \n",
        "  #Validation\n",
        "  with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      vl += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      accuracy += (predicted == labels).sum().item()\n",
        "      del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %' .format(5000, 100*accuracy / total))\n",
        "    vl = vl/len(testloader)\n",
        "    loss_val_hist16.append(vl)\n",
        "    va = accuracy/total\n",
        "    acc_val_hist16.append(va)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKa7uHKCjjzj",
        "outputId": "2e02350c-11ca-4854-df4d-8ee42cbea5d1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [391/391], Loss: 1.1424\n",
            "Accuracy of the network on the 5000 validation images: 54.55 %\n",
            "Epoch [2/10], Step [391/391], Loss: 0.8214\n",
            "Accuracy of the network on the 5000 validation images: 66.4 %\n",
            "Epoch [3/10], Step [391/391], Loss: 0.6931\n",
            "Accuracy of the network on the 5000 validation images: 69.34 %\n",
            "Epoch [4/10], Step [391/391], Loss: 0.6366\n",
            "Accuracy of the network on the 5000 validation images: 72.45 %\n",
            "Epoch [5/10], Step [391/391], Loss: 0.6355\n",
            "Accuracy of the network on the 5000 validation images: 75.76 %\n",
            "Epoch [6/10], Step [391/391], Loss: 0.5439\n",
            "Accuracy of the network on the 5000 validation images: 75.54 %\n",
            "Epoch [7/10], Step [391/391], Loss: 0.3708\n",
            "Accuracy of the network on the 5000 validation images: 76.59 %\n",
            "Epoch [8/10], Step [391/391], Loss: 0.4176\n",
            "Accuracy of the network on the 5000 validation images: 72.28 %\n",
            "Epoch [9/10], Step [391/391], Loss: 0.2320\n",
            "Accuracy of the network on the 5000 validation images: 76.33 %\n",
            "Epoch [10/10], Step [391/391], Loss: 0.0912\n",
            "Accuracy of the network on the 5000 validation images: 77.92 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Loss: \", loss_train_hist16)\n",
        "print(\"Validation Loss: \", loss_val_hist16)\n",
        "print(\"Validation Accuracy: \", acc_val_hist16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAeNwYjIj8Ow",
        "outputId": "7ead4619-c0e1-49ee-d865-027d2a6fad9f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  [1.6073968171158715, 1.054281665845905, 0.803523164880855, 0.6265657282698794, 0.48996625021290596, 0.37401105974183974, 0.28904226862484844, 0.22014851367001034, 0.175840234093349, 0.13891570475857581]\n",
            "Validation Loss:  [1.2398229731789119, 0.9484851639482039, 0.9088301258751109, 0.8253160964084577, 0.7384855788719805, 0.7837648995314972, 0.8048381035840964, 1.0485395072381707, 0.8852410407005986, 0.8627025998091395]\n",
            "Validation Accuracy:  [0.5455, 0.664, 0.6934, 0.7245, 0.7576, 0.7554, 0.7659, 0.7228, 0.7633, 0.7792]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2 Part 1"
      ],
      "metadata": {
        "id": "1vWO2DwHm0NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super(Inception, self).__init__(**kwargs)\n",
        "        # Branch 1\n",
        "        self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
        "        # Branch 2\n",
        "        self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
        "        self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
        "        # Branch 3\n",
        "        self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
        "        self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
        "        # Branch 4\n",
        "        self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        b1 = F.relu(self.b1_1(x))\n",
        "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
        "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
        "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
        "        return torch.cat((b1, b2, b3, b4), dim=1)"
      ],
      "metadata": {
        "id": "HDyBk_jYlZX7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleNet(nn.Module):\n",
        "  def b1(self):\n",
        "    return nn.Sequential(\n",
        "              nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "              nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  def b2(self):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
        "        nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  def b3(self):\n",
        "    return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
        "                         Inception(128, (128, 192), (32, 96), 64),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  def b4(self):\n",
        "    return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
        "                         Inception(160, (112, 224), (24, 64), 64),\n",
        "                         Inception(128, (128, 256), (24, 64), 64),\n",
        "                         Inception(112, (144, 288), (32, 64), 64),\n",
        "                         Inception(256, (160, 320), (32, 128), 128),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  def b5(self):\n",
        "    return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
        "                         Inception(384, (192, 384), (48, 128), 128),\n",
        "                         nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
        "  def __init__(self, lr=0.1, num_classes=10):\n",
        "    super(GoogleNet, self).__init__()\n",
        "    self.model = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
        "                             self.b5(), nn.LazyLinear(num_classes))\n",
        "  def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "G_Oq9ircpsqj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters again\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "# model = GoogleNet().to(device)\n",
        "model = GoogleNet().model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "steps = len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHYgSNQzrP2k",
        "outputId": "484e7713-5274-46c9-bd5f-c83c3d31e6eb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_histGN = []\n",
        "loss_val_histGN = []\n",
        "acc_val_histGN = []"
      ],
      "metadata": {
        "id": "rdfHjNS6riZO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  tl = 0\n",
        "  vl = 0\n",
        "  va = 0\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tl = tl + loss.item()\n",
        "\n",
        "  tl = tl/len(trainloader)\n",
        "  loss_train_histGN.append(tl)\n",
        "  print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, steps, loss.item()))\n",
        "  \n",
        "  #Validation\n",
        "  with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      vl += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      accuracy += (predicted == labels).sum().item()\n",
        "      del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %' .format(5000, 100*accuracy / total))\n",
        "    vl = vl/len(testloader)\n",
        "    loss_val_histGN.append(vl)\n",
        "    va = accuracy/total\n",
        "    acc_val_histGN.append(va)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rnUYAWJrn4z",
        "outputId": "158c8973-4511-4b47-999d-91f466a35551"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [391/391], Loss: 2.3020\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [2/10], Step [391/391], Loss: 2.3042\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [3/10], Step [391/391], Loss: 2.3032\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [4/10], Step [391/391], Loss: 2.3026\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [5/10], Step [391/391], Loss: 2.3029\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [6/10], Step [391/391], Loss: 2.3027\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [7/10], Step [391/391], Loss: 2.3026\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [8/10], Step [391/391], Loss: 2.3025\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [9/10], Step [391/391], Loss: 2.3027\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [10/10], Step [391/391], Loss: 2.3028\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2 Part 2"
      ],
      "metadata": {
        "id": "2yCG23CbDTXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleNet_BatchNorm(nn.Module):\n",
        "  def b1(self):\n",
        "    return nn.Sequential(\n",
        "              nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  def b2(self):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyConv2d(64, kernel_size=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "        nn.LazyConv2d(192, kernel_size=3, padding=1), nn.BatchNorm2d(192), nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  def b3(self):\n",
        "    return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
        "                         Inception(128, (128, 192), (32, 96), 64),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  def b4(self):\n",
        "    return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
        "                         Inception(160, (112, 224), (24, 64), 64),\n",
        "                         Inception(128, (128, 256), (24, 64), 64),\n",
        "                         Inception(112, (144, 288), (32, 64), 64),\n",
        "                         Inception(256, (160, 320), (32, 128), 128),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "  def b5(self):\n",
        "    return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
        "                         Inception(384, (192, 384), (48, 128), 128),\n",
        "                         nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
        "  def __init__(self, lr=0.1, num_classes=10):\n",
        "    super(GoogleNet_BatchNorm, self).__init__()\n",
        "    self.model = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
        "                             self.b5(), nn.LazyLinear(num_classes))\n",
        "  def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "AuhWK0GYrzrM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters again\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = GoogleNet_BatchNorm().model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "steps = len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfND6Up85u9S",
        "outputId": "899f2f4f-7aa8-478e-c3e3-ff9095cad6e3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_histGNBN = []\n",
        "loss_val_histGNBN = []\n",
        "acc_val_histGNBN = []"
      ],
      "metadata": {
        "id": "SJ3vYgln5zWO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  tl = 0\n",
        "  vl = 0\n",
        "  va = 0\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tl = tl + loss.item()\n",
        "\n",
        "  tl = tl/len(trainloader)\n",
        "  loss_train_histGNBN.append(tl)\n",
        "  print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, steps, loss.item()))\n",
        "  \n",
        "  #Validation\n",
        "  with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      vl += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      accuracy += (predicted == labels).sum().item()\n",
        "      del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %' .format(5000, 100*accuracy / total))\n",
        "    vl = vl/len(testloader)\n",
        "    loss_val_histGNBN.append(vl)\n",
        "    va = accuracy/total\n",
        "    acc_val_histGNBN.append(va)"
      ],
      "metadata": {
        "id": "rZ4p-nlr6DMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52dd6d6f-fc27-4aa8-8ff3-f4bda83dac0c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [391/391], Loss: 2.3019\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [2/10], Step [391/391], Loss: 2.3022\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [3/10], Step [391/391], Loss: 2.3021\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [4/10], Step [391/391], Loss: 2.3026\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [5/10], Step [391/391], Loss: 2.3026\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [6/10], Step [391/391], Loss: 2.3026\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [7/10], Step [391/391], Loss: 2.3027\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [8/10], Step [391/391], Loss: 2.3027\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [9/10], Step [391/391], Loss: 2.3026\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n",
            "Epoch [10/10], Step [391/391], Loss: 2.3028\n",
            "Accuracy of the network on the 5000 validation images: 10.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Loss: \", loss_train_histGNBN)\n",
        "print(\"Validation Loss: \", loss_val_histGNBN)\n",
        "print(\"Validation Accuracy: \", acc_val_histGNBN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXo0-ng6RvKu",
        "outputId": "b2abaa70-0e34-484b-c769-966f754c8d19"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  [2.302711688649014, 2.302656273707709, 2.302641714320463, 2.3026312062197634, 2.3026287567889905, 2.3026301568121554, 2.302628259829548, 2.30263233733604, 2.3026280531188106, 2.3026290994775875]\n",
            "Validation Loss:  [2.3026705180542377, 2.3026282002654255, 2.3025933126860028, 2.302576928199092, 2.3025879950463017, 2.302588094638873, 2.302588888361484, 2.3025862506673307, 2.302584968035734, 2.3025817086425007]\n",
            "Validation Accuracy:  [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2 Part 1 - Attempt 2 (Still doesn't work)"
      ],
      "metadata": {
        "id": "1vH8fcBM6oDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleNetNew(nn.Module):\n",
        "  def __init__(self, in_channels=3, num_classes=10):\n",
        "    super(GoogleNetNew, self).__init__()\n",
        "\n",
        "    self.conv1 = conv_block(in_channels=in_channels, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.inception3a = InceptionNew(192, 64, 96, 128, 16, 32, 32)\n",
        "    self.inception3b = InceptionNew(256, 128, 128, 192, 32, 96, 64)\n",
        "    self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.inception4a = InceptionNew(480, 192, 96, 208, 16, 48, 64)\n",
        "    self.inception4b = InceptionNew(512, 160, 112, 224, 24, 64, 64)\n",
        "    self.inception4c = InceptionNew(512, 128, 128, 256, 24, 64, 64)\n",
        "    self.inception4d = InceptionNew(512, 112, 144, 288, 32, 64, 64)\n",
        "    self.inception4e = InceptionNew(528, 256, 160, 320, 32, 128, 128)\n",
        "\n",
        "    self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.inception5a = InceptionNew(832, 256, 160, 320, 32, 128, 128)\n",
        "    self.inception5b = InceptionNew(832, 384, 192, 384, 48, 128, 128)\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    self.fc1 = nn.Linear(1024, 1000)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "\n",
        "    x = self.inception3a(x)\n",
        "    x = self.inception3b(x)\n",
        "    x = self.maxpool3(x)\n",
        "\n",
        "    x = self.inception4a(x)\n",
        "    x = self.inception4b(x)\n",
        "    x = self.inception4c(x)\n",
        "    x = self.inception4d(x)\n",
        "    x = self.inception4e(x)\n",
        "    x = self.maxpool4(x)\n",
        "\n",
        "    x = self.inception5a(x)\n",
        "    x = self.inception5b(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class InceptionNew(nn.Module):\n",
        "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n",
        "        super(InceptionNew, self).__init__()\n",
        "        # Branch 1\n",
        "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n",
        "        # Branch 2\n",
        "        self.branch2 = nn.Sequential(\n",
        "            conv_block(in_channels, red_3x3, kernel_size=1),\n",
        "            conv_block(red_3x3, out_3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "        # Branch 3\n",
        "        self.branch3 = nn.Sequential(\n",
        "            conv_block(in_channels, red_5x5, kernel_size=1),\n",
        "            conv_block(red_5x5, out_5x5, kernel_size=5, padding=2)\n",
        "        )\n",
        "        # Branch 4\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            conv_block(in_channels, out_1x1pool, kernel_size=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, **kwargs):\n",
        "    super(conv_block, self).__init__()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
        "    self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.relu(self.batchnorm(self.conv(x)))"
      ],
      "metadata": {
        "id": "Tv-_8eT56eSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters again\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = GoogleNetNew().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "steps = len(trainloader)"
      ],
      "metadata": {
        "id": "wI0tkYIrAWNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_histGNBN = []\n",
        "loss_val_histGNBN = []\n",
        "acc_val_histGNBN = []"
      ],
      "metadata": {
        "id": "ELlBGC57Ackx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  tl = 0\n",
        "  vl = 0\n",
        "  va = 0\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tl = tl + loss.item()\n",
        "\n",
        "  tl = tl/len(trainloader)\n",
        "  loss_train_hist16.append(tl)\n",
        "  print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, steps, loss.item()))\n",
        "  \n",
        "  #Validation\n",
        "  with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      vl += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      accuracy += (predicted == labels).sum().item()\n",
        "      del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %' .format(5000, 100*accuracy / total))\n",
        "    vl = vl/len(testloader)\n",
        "    loss_val_hist16.append(vl)\n",
        "    va = accuracy/total\n",
        "    acc_val_hist16.append(va)"
      ],
      "metadata": {
        "id": "fkiIHSMmAgh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 3 Part 1"
      ],
      "metadata": {
        "id": "oL9oXhrjCKGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
        "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
        "                                   stride=strides)\n",
        "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "    def block(self, num_residuals, num_channels, first_block=False):\n",
        "      blk = []\n",
        "      for i in range(num_residuals):\n",
        "          if i == 0 and not first_block:\n",
        "              blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "          else:\n",
        "              blk.append(Residual(num_channels))\n",
        "      return nn.Sequential(*blk)\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "      super(ResNet, self).__init__()\n",
        "      self.net = nn.Sequential(self.b1())\n",
        "      for i, b in enumerate(arch):\n",
        "          self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "      self.net.add_module('last', nn.Sequential(\n",
        "          nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "          nn.LazyLinear(num_classes)))\n",
        "    def forward(self, x):\n",
        "      return self.net(x)"
      ],
      "metadata": {
        "id": "YGnV7bBqAhRg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(ResNet):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)), num_classes)"
      ],
      "metadata": {
        "id": "Qu18DMnuDgRM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters again\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = ResNet18().net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "steps = len(trainloader)"
      ],
      "metadata": {
        "id": "EvlNzQaJGISm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_histR18 = []\n",
        "loss_val_histR18 = []\n",
        "acc_val_histR18 = []"
      ],
      "metadata": {
        "id": "ldIRRDqgH3XO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  tl = 0\n",
        "  vl = 0\n",
        "  va = 0\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tl = tl + loss.item()\n",
        "\n",
        "  tl = tl/len(trainloader)\n",
        "  loss_train_histR18.append(tl)\n",
        "  print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, steps, loss.item()))\n",
        "  \n",
        "  #Validation\n",
        "  with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      vl += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      accuracy += (predicted == labels).sum().item()\n",
        "      del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %' .format(5000, 100*accuracy / total))\n",
        "    vl = vl/len(testloader)\n",
        "    loss_val_histR18.append(vl)\n",
        "    va = accuracy/total\n",
        "    acc_val_histR18.append(va)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vyLMVv7H9hH",
        "outputId": "5d05db9c-3954-421d-bf95-752f00176ec3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [391/391], Loss: 1.1079\n",
            "Accuracy of the network on the 5000 validation images: 54.9 %\n",
            "Epoch [2/10], Step [391/391], Loss: 1.2685\n",
            "Accuracy of the network on the 5000 validation images: 59.83 %\n",
            "Epoch [3/10], Step [391/391], Loss: 0.8017\n",
            "Accuracy of the network on the 5000 validation images: 65.13 %\n",
            "Epoch [4/10], Step [391/391], Loss: 0.7614\n",
            "Accuracy of the network on the 5000 validation images: 67.06 %\n",
            "Epoch [5/10], Step [391/391], Loss: 0.8245\n",
            "Accuracy of the network on the 5000 validation images: 67.32 %\n",
            "Epoch [6/10], Step [391/391], Loss: 0.6814\n",
            "Accuracy of the network on the 5000 validation images: 65.93 %\n",
            "Epoch [7/10], Step [391/391], Loss: 0.4910\n",
            "Accuracy of the network on the 5000 validation images: 66.3 %\n",
            "Epoch [8/10], Step [391/391], Loss: 0.6207\n",
            "Accuracy of the network on the 5000 validation images: 66.94 %\n",
            "Epoch [9/10], Step [391/391], Loss: 0.4444\n",
            "Accuracy of the network on the 5000 validation images: 67.05 %\n",
            "Epoch [10/10], Step [391/391], Loss: 0.2172\n",
            "Accuracy of the network on the 5000 validation images: 68.47 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Loss: \", loss_train_histR18)\n",
        "print(\"Validation Loss: \", loss_val_histR18)\n",
        "print(\"Validation Accuracy: \", acc_val_histR18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeSm9KcUTMUM",
        "outputId": "4b3b44af-d6b5-467a-a6da-ec2ab08034be"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  [1.4365338596236674, 1.0555495563370492, 0.8613864973073115, 0.7174634493677817, 0.6004056185865037, 0.4920523040892218, 0.4047490801576458, 0.3291359624594374, 0.26939818000092225, 0.21808702782596773]\n",
            "Validation Loss:  [1.2684783995906008, 1.1421971517273142, 0.9839184857621978, 0.9783547716804698, 0.9849975124190126, 1.0720300614079343, 1.1216949862015397, 1.1789754131172276, 1.1776849740668187, 1.212127279631699]\n",
            "Validation Accuracy:  [0.549, 0.5983, 0.6513, 0.6706, 0.6732, 0.6593, 0.663, 0.6694, 0.6705, 0.6847]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 3 Part 2"
      ],
      "metadata": {
        "id": "SLvcSEXkTGRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet26(ResNet):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__(((6, 64), (6, 128), (2, 256), (2, 512)), num_classes)"
      ],
      "metadata": {
        "id": "4kbC-GLlIC6u"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters again\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = ResNet26().net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "steps = len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcFDRvu1SwtX",
        "outputId": "52258446-cac8-43bf-b7fe-b9618c42690c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_histR26 = []\n",
        "loss_val_histR26 = []\n",
        "acc_val_histR26 = []"
      ],
      "metadata": {
        "id": "Io1LOPGCTiRA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  tl = 0\n",
        "  vl = 0\n",
        "  va = 0\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tl = tl + loss.item()\n",
        "\n",
        "  tl = tl/len(trainloader)\n",
        "  loss_train_histR26.append(tl)\n",
        "  print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, steps, loss.item()))\n",
        "  \n",
        "  #Validation\n",
        "  with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      vl += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      accuracy += (predicted == labels).sum().item()\n",
        "      del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %' .format(5000, 100*accuracy / total))\n",
        "    vl = vl/len(testloader)\n",
        "    loss_val_histR26.append(vl)\n",
        "    va = accuracy/total\n",
        "    acc_val_histR26.append(va)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoteTheMTozF",
        "outputId": "6d7bcc39-35bd-4c66-b951-5f7785c1fa02"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [391/391], Loss: 0.9985\n",
            "Accuracy of the network on the 5000 validation images: 54.56 %\n",
            "Epoch [2/10], Step [391/391], Loss: 1.1778\n",
            "Accuracy of the network on the 5000 validation images: 61.18 %\n",
            "Epoch [3/10], Step [391/391], Loss: 0.8650\n",
            "Accuracy of the network on the 5000 validation images: 62.57 %\n",
            "Epoch [4/10], Step [391/391], Loss: 0.7603\n",
            "Accuracy of the network on the 5000 validation images: 66.54 %\n",
            "Epoch [5/10], Step [391/391], Loss: 0.5502\n",
            "Accuracy of the network on the 5000 validation images: 67.98 %\n",
            "Epoch [6/10], Step [391/391], Loss: 0.4132\n",
            "Accuracy of the network on the 5000 validation images: 66.96 %\n",
            "Epoch [7/10], Step [391/391], Loss: 0.6480\n",
            "Accuracy of the network on the 5000 validation images: 67.17 %\n",
            "Epoch [8/10], Step [391/391], Loss: 0.3760\n",
            "Accuracy of the network on the 5000 validation images: 68.14 %\n",
            "Epoch [9/10], Step [391/391], Loss: 0.3465\n",
            "Accuracy of the network on the 5000 validation images: 68.4 %\n",
            "Epoch [10/10], Step [391/391], Loss: 0.3671\n",
            "Accuracy of the network on the 5000 validation images: 68.05 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Loss: \", loss_train_histR26)\n",
        "print(\"Validation Loss: \", loss_val_histR26)\n",
        "print(\"Validation Accuracy: \", acc_val_histR26)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_YP7UrhUjbb",
        "outputId": "311b36f0-ac18-46b4-8853-1ec8f635dc10"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  [1.4791089508234692, 1.0870997795973287, 0.8975861095406515, 0.7602958761517654, 0.6509163328601272, 0.5467354233002724, 0.4678100241190942, 0.3884990331919297, 0.3200858277280617, 0.2683706575876002]\n",
            "Validation Loss:  [1.2665251765070082, 1.0872121332566949, 1.084966207606883, 0.9801287771780279, 0.9527796371073662, 1.0477795887597, 1.0796845879735826, 1.0914713951605786, 1.0928650226774095, 1.1798695959622347]\n",
            "Validation Accuracy:  [0.5456, 0.6118, 0.6257, 0.6654, 0.6798, 0.6696, 0.6717, 0.6814, 0.684, 0.6805]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet32(ResNet):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__(((8, 64), (6, 128), (4, 256), (4, 512)), num_classes)"
      ],
      "metadata": {
        "id": "oBaw-bcCTy0n"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyperparameters again\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = ResNet32().net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "steps = len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29JYlbLvUK6V",
        "outputId": "217ef945-3f23-4b0a-9f52-4466c4bb4d33"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_histR32 = []\n",
        "loss_val_histR32 = []\n",
        "acc_val_histR32 = []"
      ],
      "metadata": {
        "id": "l67bAgerUPAB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  tl = 0\n",
        "  vl = 0\n",
        "  va = 0\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tl = tl + loss.item()\n",
        "\n",
        "  tl = tl/len(trainloader)\n",
        "  loss_train_histR32.append(tl)\n",
        "  print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, steps, loss.item()))\n",
        "  \n",
        "  #Validation\n",
        "  with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      vl += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      accuracy += (predicted == labels).sum().item()\n",
        "      del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %' .format(5000, 100*accuracy / total))\n",
        "    vl = vl/len(testloader)\n",
        "    loss_val_histR32.append(vl)\n",
        "    va = accuracy/total\n",
        "    acc_val_histR32.append(va)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12AWiuyoUVR2",
        "outputId": "8d35d1a7-8bee-45d1-e78d-53164c8ac040"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [391/391], Loss: 1.2615\n",
            "Accuracy of the network on the 5000 validation images: 51.25 %\n",
            "Epoch [2/10], Step [391/391], Loss: 1.0333\n",
            "Accuracy of the network on the 5000 validation images: 56.48 %\n",
            "Epoch [3/10], Step [391/391], Loss: 1.1554\n",
            "Accuracy of the network on the 5000 validation images: 60.32 %\n",
            "Epoch [4/10], Step [391/391], Loss: 0.7903\n",
            "Accuracy of the network on the 5000 validation images: 64.55 %\n",
            "Epoch [5/10], Step [391/391], Loss: 0.8654\n",
            "Accuracy of the network on the 5000 validation images: 67.11 %\n",
            "Epoch [6/10], Step [391/391], Loss: 0.7178\n",
            "Accuracy of the network on the 5000 validation images: 67.07 %\n",
            "Epoch [7/10], Step [391/391], Loss: 0.6093\n",
            "Accuracy of the network on the 5000 validation images: 67.4 %\n",
            "Epoch [8/10], Step [391/391], Loss: 0.5934\n",
            "Accuracy of the network on the 5000 validation images: 66.46 %\n",
            "Epoch [9/10], Step [391/391], Loss: 0.4350\n",
            "Accuracy of the network on the 5000 validation images: 69.13 %\n",
            "Epoch [10/10], Step [391/391], Loss: 0.4881\n",
            "Accuracy of the network on the 5000 validation images: 66.15 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Loss: \", loss_train_histR32)\n",
        "print(\"Validation Loss: \", loss_val_histR32)\n",
        "print(\"Validation Accuracy: \", acc_val_histR32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMORjCJbUedm",
        "outputId": "5f2cffd5-999f-4973-daf0-23a041fbbacb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  [1.569885929222302, 1.1647049842588126, 0.9661072058141079, 0.8190585077571138, 0.7094748987413734, 0.6108789835744501, 0.520918270358649, 0.4359185559213009, 0.3718055216476436, 0.3178015544134028]\n",
            "Validation Loss:  [1.3395561462716212, 1.2234503815445719, 1.118164963360074, 1.0259436761276632, 0.9712043208411977, 0.9755441418176964, 1.0267728635027438, 1.1149966807305058, 1.063697961312306, 1.2335963513277755]\n",
            "Validation Accuracy:  [0.5125, 0.5648, 0.6032, 0.6455, 0.6711, 0.6707, 0.674, 0.6646, 0.6913, 0.6615]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_cbbYUqUsYr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}